{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcunqdBEfQRUe6LgA4b/cc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TUIlmenauAMS/GVT_Lecture_Colab/blob/main/GVT_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture Fundamentals of Video Technology**\n",
        "\n",
        "## Gerald Schuller\n",
        "\n",
        "## Gerald.schuller@tu-ilmenau.de\n"
      ],
      "metadata": {
        "id": "13QGqZUbvo8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Python Video/Image Introduction**"
      ],
      "metadata": {
        "id": "gF6JdgsLwcjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####common Linux console Commands:\n",
        "“**man**” Command : manual pages (explanation) for „command“.\n",
        "Example: man cd\n",
        "\n",
        "**cd** : changes directory, \"/\" : root directory, \".\" : current directory, „..“ : one directory higher.\n",
        "Example: cd ..\n",
        "\n",
        "**pwd** : print working directory\n",
        "\n",
        "**ps** : print running processes\n",
        "\n",
        "**ps -ef | more** print all processes page by page\n",
        "\n",
        "**ps -ef | grep process-name** : Outputs the details of the process specified by its name.\n",
        "\n",
        "**kill Number**: ends program or process with process ID \"Number\", previously seen with ps.\n",
        "\n",
        "**df** : disk free\n",
        "\n",
        "**du** : disk usage, shows usage for directories\n",
        "\n",
        "**whoami** : prints username\n",
        "\n",
        "**finger username** : print information about username\n",
        "\n",
        "**date** : shows date and time\n",
        "\n",
        "**time** : measures time of a command run, e.g. time ls\n",
        "\n",
        "**who** : shows who is logged in\n",
        "\n",
        "**uptime**: Shows time since last boot\n",
        "\n",
        "**top** : shows processes sorted by cpu suage\n",
        "\n",
        "**mv *filename* destination** : move “filename” to “destination” directory.  \n",
        "\n",
        "**rm** : remove\n",
        "\n",
        "**mkdir** : makes directory\n",
        "\n",
        "**cat** : concatenate, output the contents of a file\n",
        "\n",
        "**more** : shows an input or file one page at a time, more filename, or from input e.g.: ls | more\n",
        "\n",
        "**xterm** : start x-terminal\n",
        "\n",
        "**which command** : shows path to command\n",
        "\n",
        "**shutdown now** : shuts down computer now\n",
        "\n",
        "**vi** : visual editor: terminal based editor. commands:esc: commmand mode, in command mode: :w write, :q quit, x delete character, i insert in write mode (enter text) \n",
        "\n",
        "**ssh** : secure shell, e.g. ssh servername \n",
        "\n",
        "**man** : manual pages, e.g. man ssh\n",
        "\n",
        "**cp** : copy a file or directory, e.g. cp filename directory, original is kept, unlike with „mv“.\n",
        "\n",
        "**scp** : secure copy, between networked machines, e.g. scp . user@remotemachine.edu:dir \n",
        "\n",
        "**chmod** : change mode: change access rights for files or directories. To make a file executable: chmod ug+x file. User and group get the right to execute the file.\n",
        "\n",
        "**ifconfig** : show network data like ip address \n",
        "\n",
        "**sox** : audio tools, e.g. command \"play\" \n",
        "\n",
        "**wget** : copy entire website trees"
      ],
      "metadata": {
        "id": "Ho-aRjT7wkBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Debugging** is an essential part of programming. An essential strategy for this is: divide the program into several simple functions with known input/output relationship, and then test them separately."
      ],
      "metadata": {
        "id": "R3LC6CsWwnd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Image Processing**\n",
        "In the console window install python3-opencv (if not already done). This is the so-called Open Computer Vision Library:"
      ],
      "metadata": {
        "id": "tuKVGlI6-P1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt install python3-opencv\n",
        "ipython3 –pylab\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Htk1x5VQ-ZMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Interesting commands in ipython --pylab:\n",
        "\n",
        "help(name of function)  or function name: \n",
        "help function for the command\n",
        "\n",
        "Example:\n",
        "help(sin)"
      ],
      "metadata": {
        "id": "8kYFNRo2-iOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Useful commands:\n",
        "\n",
        "cv2.imread, for reading JPEG images from a file, \n",
        "\n",
        "cv2.imwrite, for writing JPEG images in a file,\n",
        "\n",
        "cv2.imshow, for plotting images from arrays,\n",
        "\n",
        "imshow, (From the library matplotlib.pyplot already loaded by --pylab, potential name conflict!)"
      ],
      "metadata": {
        "id": "TndRdY9D-soT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example:**\n",
        "Take a photo with our python script „imagerecdisp.py“ with command line:\n",
        "\n",
        "python3 imagerecdisp.py\n",
        "\n",
        "Then we start Python, import cv2, and read Photo with:\n",
        "\n",
        "import cv2\n",
        "photo=cv2.imread('pycolorphoto.jpg');"
      ],
      "metadata": {
        "id": "5-cd94p0-5pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the size of image with „shape“:\n",
        "\n",
        "print(\"Photo dimensions:\",photo.shape)\n",
        "\n",
        "('Photo dimensions:', (480, 640, 3))\n"
      ],
      "metadata": {
        "id": "Rjr88CQr_B7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, 480 and 640 are the number of pixels in the image ,vertically and horizontally. The number “3” comes from the 3 primary colors red, green and blue (RGB). Note that Python OpenCV stores it in the order “BGR”. That means, “0” is blue, “1” is green and “2” is red.\n",
        "\n",
        "\n",
        "Here we can have access to the individual pixels, e.g. the Pixel at position 0,0 has a proportion of the primary color blue from:\n",
        "photo[0,0,0]\n",
        "\n",
        "  88\n",
        "  \n",
        "The \"88\" is an intensity value, which is between 0 and 255 for images (corresponding to 8 bits unsigned integer per primary color intensity value)."
      ],
      "metadata": {
        "id": "B__EDKRM_GCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can represent the image in the matrix ortensor ”photo\" with the command:\n",
        "\n",
        "cv2.imshow('Photo',photo)\n",
        "\n",
        "To display the image we need:\n",
        "\n",
        "cv2.waitKey(1000)\n",
        "\n",
        "1000 means: The image is displayed for 1000ms, and then the key-press from the keyboard is queried.\n",
        "\n",
        "The following shows the display of the blue component intensity value of the image:\n",
        "\n",
        "cv2.imshow('Blue-component',photo[:,:,0])\n",
        "\n",
        "cv2.waitKey(1000)\n"
      ],
      "metadata": {
        "id": "1KhRVxlR_Mh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Video processing**\n",
        "\n",
        "The OpenCV library also gives us the possibility to stream data directly from a webcam in computer, such as with the Raspberry Pi!\n",
        "\n",
        "For this purpose, the command is:\n",
        "\n",
        "cap = cv2.VideoCapture(0) "
      ],
      "metadata": {
        "id": "Avr0H7SM_ct3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This accesses the default camera 0, which is for example an inserted USB webcam.\"Cap\" contains a pointer to the address of this camera.\n",
        "We can read a frame of this stream as:\n",
        "\n",
        " [retval, frame] = cap.read()\n",
        "\n",
        "where \"retval\" is a return value (it says if everything is fine), and \"frame\" contains the \n",
        "obtained frame.\n",
        "\n",
        "With\n",
        "\n",
        "cv2.imshow('frame',frame)\n",
        "\n",
        "we can display this frame in a window.\n",
        "\n",
        "With the following function,\n",
        "\n",
        "cv2.waitKey(..)\n",
        "\n",
        "the **window** is **opened** by cv2.imshow (it does not open without waitKey) and remains open until a keypress event is prompted by waitKey function. The function cv2.waitkey waits for a key event, and it is only active if the corresponding window is active.Only when this window is active, cv2.waitKey responds to keyboard input!\n",
        "When we do this in an infinite loop, we get the live video of the camera displayed in the window. A sample program for this is:"
      ],
      "metadata": {
        "id": "L5ZIyTib_nWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#Program to capture a video from the default camera (0) and display it live on the screen \n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(True):\n",
        "    # Capture frame-by-frame\n",
        "    [retval, frame] = cap.read()    \n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('frame',frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "0vHQQ9uX_7nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save it as \"videorecdisp.py\" and then call it from console window/terminal with:\n",
        "\n",
        "python videorecdisp.py\n",
        "\n",
        "and we obtain the live video. End the video display by pressing “q”.\n",
        "\n",
        "A practical usage is e.g. a \"pipe camera\" with goose-neck for the pipes inspection.\n",
        "\n",
        "The following example captures an image of the live video from our camera:"
      ],
      "metadata": {
        "id": "XKmnZP3S_-YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#Program to capture an image from a camera and display it live on the screen\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# Capture frame\n",
        "ret, frame = cap.read()\n",
        "\n",
        "# Display the resulting frame\n",
        "cv2.imshow('frame',frame)\n",
        "\n",
        "cv2.imwrite('pycolorphoto.jpg', frame)\n",
        "\n",
        "while(True):\n",
        "   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "WJqwSmTgAFCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save it with the name \"imagerecdisp.py\" and start it with:\n",
        "\n",
        "python imagerecdisp.py\n",
        "\n",
        "Immediately after the start the photo is shot and displayed. The display will be terminated with \"q\".\n",
        "\n",
        "The following example shows the contents of the top left pixel of the video when the program is started:"
      ],
      "metadata": {
        "id": "Co0CF0mpAHek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#Program to capture an image from a camera and display the pixel value on the screen\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Capture one frame\n",
        "[ret, frame] = cap.read()\n",
        "\n",
        "print(\"image format: \", frame.shape)\n",
        "print(\"pixel 0,0: \",frame[0,0,:])"
      ],
      "metadata": {
        "id": "FFLijr_5ALxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save it as \"pyimageshowpixel.py\" and start it with:\n",
        "\n",
        "python  pyimageshowpixel.py\n",
        "\n",
        "Output:\n",
        "\n",
        "('image format: ', (480, 640, 3))\n",
        "('pixel 0,0: ', array([ 35, 167, 146], dtype=uint8))\n"
      ],
      "metadata": {
        "id": "TqE9N78TAPXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we had only addressed the pixel position, so only first 2 indices: frame [0,0 ,:]."
      ],
      "metadata": {
        "id": "-YzbzSexAYPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **colon** \":\" means that all indices of this dimension (i.e., indices for intensities of B,G,R)  are addressed.\n",
        "\n",
        "In this way, we could also address an index range, by **Start:End**, e.g, 0:3 addresses the indices 0,1,2 (Note: not the End value, 3). In this case, the above mentioned notation i.e., frame[0,0,:] is identical to:\n",
        "frame[0,0,0:3]\n",
        "\n",
        "As output, we get not only a value, but an array with the values of the 3 primary colors, in the order BGR. \"Red\" here has the value 146, Green 167, and Blue 35.\n",
        "We also see that the number representation is \"uint8\", which means: unsigned integer with 8 bits, that is, a number between 0 and 255 (= 28−1 ).  \n"
      ],
      "metadata": {
        "id": "ke-7Ql2KAa0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the following program we can analyze the R, G, and B components as video in separate windows:"
      ],
      "metadata": {
        "id": "JE3E_mjGAiNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#Program to capture a video from a camera and display Original and R,G,B, components live on the screen\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "cv2.namedWindow('Original')\n",
        "cv2.namedWindow('B component')\n",
        "cv2.namedWindow('G component')\n",
        "cv2.namedWindow('R component')\n",
        "\n",
        "while(True):\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Original',frame)\n",
        "    cv2.imshow('B Komponente',frame[:,:,0])\n",
        "    cv2.imshow('G Komponente',frame[:,:,1])\n",
        "    cv2.imshow('R Komponente',frame[:,:,2])\n",
        " \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
        "        break \n",
        "\n",
        "# When everything done, release the capture \n",
        "cap.release() \n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Gu-vfCXLAkOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name it videorecdispRGB.py and start it in console window with: \n",
        "\n",
        "python videorecdispRGB.py"
      ],
      "metadata": {
        "id": "yOzqL69UArOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The colors belonging to the respective component (R, G, B) appear lighter in the corresponding video.\n",
        "\n",
        "Here we can see: Each pixel requires an information content of 3 bytes (byte = 8bit). We have 480x640 pixels, that is, 307200 pixels per frame. If we have 25 frames per second, we get about 307200 * 25 * 3 * 8 bits per second (b/s), ie 184320000 b/s, about 184 Mb/s! This is significantly more than most Internet connections offer, let alone for wireless transmission.\n",
        "\n",
        "We should think, for a (wireless) transmission, how we **reduce** the necessary **bitrate**.\n",
        "A simple method is to transmit only **black and white video** content instead of color content which brings a bitrate reduction by a factor of 3. \n",
        "\n",
        "In order to produce the correct brightness impression, we must take into account the relative, different sensitivity of the human eye to the 3 primary colors. By empirical examination of the subjective brightness the following relation was obtained for the primary colors R, G, B:\n",
        "\n",
        "0.299; 0.587; 0.114\n",
        "\n",
        "We see: The eye is most sensitive to the primary color green, followed by red, and significantly less to blue.\n",
        "\n",
        "So if we weight the primary color values of our video, we get a matching black and white image. Its brightness value is denoted by Y:\n",
        "\n",
        "Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
        "\n",
        "Note: Since the sum of the 3 factors is equal to 1, Y has the same range of values as R, G, B.\n"
      ],
      "metadata": {
        "id": "PRmfOHdjAs9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python example** to compute the so-called “Luminance” component Y, the brightness, or the Black/White version of image. For comparison is the „Green“ component is also displayed:\n",
        "\n",
        "python videorecprocy.py\n",
        "\n",
        "In this script the Y component is computed with:\n",
        "\n",
        "Y=(0.114 * frame[: , : , 0] + 0.587 * frame[: , : , 1] + 0.299 * frame[: , : , 2]) / 255;"
      ],
      "metadata": {
        "id": "pqNbmb_6BFZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: We can simply **multiply a frame by a float value**. The division at the end is expected to normalize to the value range of 0..1, the Python is expected at float values for the frame.\n",
        "\n",
        "**Note**: Y best reproduces the human brightness impression, the green component is a certain approximation of it.\n",
        "\n",
        "However a black/white transmission is not very satisfactory. So how can we transfer **color** with a relatively **low bit-rate**?\n",
        "\n",
        "How many pixels do we need for a good quality display?\n",
        "\n",
        "To answer these questions, we must look at the **properties of the eye**.\n"
      ],
      "metadata": {
        "id": "QWqQxkPOBK6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Audio Processing**\n",
        "In the console window install **python3-pyaudio** (if not already done):\n",
        "\n",
        "*sudo apt install python3-pyaudio*\n",
        "\n",
        "This allows python access to the sound card or device. The following program is an example of how to record audio from the microphone and store it into a file named in the argument,\n",
        "\n",
        "*python3 pyrecaudiofile.py test.wav*\n",
        "\n",
        "Important parameters are:\n",
        "\n",
        "- CHUNK = 1024 #Blocksize, number of audio samples read from the sound card at once.\n",
        "\n",
        "- WIDTH = 2 #2 bytes per audio sample, or 16 bits.\n",
        "\n",
        "- CHANNELS = 1 # number of audio channels, 1 for mono, 2 for stereo\n",
        "\n",
        "- RATE = 16000  #Sampling Rate in Hz or audio samples per second\n"
      ],
      "metadata": {
        "id": "BOlSgIGhBv6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next program is an example of how to read an audio signal from a wav file, named in the argument, and played back through the sound device,\n",
        "\n",
        "*python3 pyplayfile test.wav*"
      ],
      "metadata": {
        "id": "qVa1Xy9YCJkw"
      }
    }
  ]
}