{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSSd9JXlVtM5fUpeg7/Ze0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TUIlmenauAMS/GVT_Lecture_Colab/blob/main/GVT_V6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture Fundamentals of Video Technology**\n",
        "\n",
        "## Gerald Schuller\n",
        "\n",
        "## Gerald.schuller@tu-ilmenau.de"
      ],
      "metadata": {
        "id": "tyyMmIriguSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The “Discrete Cosine Transform” (DCT)**\n",
        "We saw: The DFT produces a complex-valued spectrum, which is symmetric at its center (the Nyquist frequency), when we have real-valued signals. \n",
        "\n",
        "Due to this symmetry we could actually **focus on** the spectral-coefficients on the **first half of our spectrum**, and so we would have a twice as high frequency resolution.\n",
        "\n",
        "The complex-valued computation is more complex in an implementation, and for real-valued signals is mostly not necessary. Here, a **real-valued compuation** would be enough.\n",
        "\n",
        "Both points are addressed by the DCT. It can be seen as a **real-valued version** of DFT , which calculates only the first half of the spectrum, therefore with **double as high spectral coefficient-density**.\n",
        "\n",
        "There is a range of different DCT types. The common type used in **Video coding is so called “DCT Type 2”**."
      ],
      "metadata": {
        "id": "ScmXlR8hgQqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our signal $x(n)$ with length N and spectral-coefficients $y(k)$ it is defined as :\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U-Sl8LQUgoY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " $$y(k) = \n",
        "  \\begin{cases} \n",
        "   \\sqrt{\\frac{2}{N}}\\sum_{n=0}^{N-1}x(n)cos(\\frac{π}{N}⋅k⋅(n+0.5)) & \\text{for } k =1,...N-1 \\\\\n",
        " ^ \\frac{1}{\\sqrt{N}}   \\sum_{n=0}^{N-1}x(n)    & \\text{for } k = 0\n",
        "  \\end{cases}$$\n"
      ],
      "metadata": {
        "id": "3t_F2M5Ujgpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The factors with the root are needed to obtain a so called **“orthogonal” Transformation** (where the inverse transform matrix is the transpose matrix). \n",
        "\n",
        "Observe that the DCT coefficients y(k) can also be **negative** for k>0 even for all positve inputs x (because the cosine can become negative)! \n",
        "\n",
        "Here the **energy of signal** (the sum of squares of sample values $x(n)$ )  is **equal to the energy of spectral coefficients** (the sum of squares of $y(k)$ ). This is the so called “**Parseval Theorem**”. This concept originally stems from  the Fourier Transform and DFT, which have this property with proper orthogonality factors too.\n",
        "\n",
        "Note that the DCT also can be written as  matrix-multiplication with a “**Transform Matrix**”,  $T$ , with:"
      ],
      "metadata": {
        "id": "bQcWvKzXk0LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$x:=[x(0),...,x(N-1)]$$\n",
        "$$y:=[y(0),...,y(n-1)]$$\n",
        "\n",
        "$$\\begin{equation*}\n",
        "T = \\sqrt{\\frac{2}{N}}\n",
        "\\begin{bmatrix}\n",
        "\\frac{1}{\\sqrt{2}} & cos(\\frac{π}{N}⋅1⋅(0+0.5) & ,..., & cos(\\frac{π}{N}⋅(N-1)⋅(0+0.5) \\\\\n",
        ". & . &  & . \\\\\n",
        ". &  & . & .\\\\\n",
        ". &  &  & .\\\\\n",
        "\\frac{1}{\\sqrt{2}} & cos(\\frac{π}{N}⋅1⋅(N-1+0.5) & ,..., & cos(\\frac{π}{N}⋅(N-1)⋅(N-1+0.5)\n",
        "\\end{bmatrix}\n",
        "\\end{equation*}$$"
      ],
      "metadata": {
        "id": "fyyrLxEzhvJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the DCT is simply a matrix-multiplication:\n",
        "\n",
        "$$y=x⋅T$$\n",
        "\n",
        "(The same can also be done for the DFT.)"
      ],
      "metadata": {
        "id": "-X24j_jkoJ6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **inverse DCT** corresponds to a multiplication of vector **$y$** with **inverse Transform-Matrix**, which in this case, due to the **orthogonality**, is simply the **transposed matrix** :\n",
        "\n",
        "$$x=y⋅T^{-1}=y⋅T^{T}$$\n",
        "\n",
        "This corresponds to formula:\n",
        "\n",
        "$$x(n)=\\frac{y(0)}{\\sqrt{N}}+\\sqrt{\\frac{2}{N}}\\sum_{k=1}^{N-1}y(k)cos(\\frac{π}{N}⋅k⋅(n+0.5))$$\n",
        "\n",
        "for $n=0,...,N-1$"
      ],
      "metadata": {
        "id": "z9kbCDaYoQpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Python DCT Functions:**\n",
        "In Python, the function “dct” is in the Library “scipy.fftpack”. Accordingly the function for an  orthogonal DCT of type 2 is :\n"
      ],
      "metadata": {
        "id": "3auN1whvpEsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "y=scipy.fftpack.dct(x,type=2,axis=1,norm='ortho') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "7J0qsk18pbZj",
        "outputId": "f60cd346-9a25-4510-91e3-51a63c6c63ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-379b2bc247c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ortho'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The option “type=2” is the default setting too, therefore can be omitted. “axis” specifies in which dimension or direction the DCT should be used . “1” is along the rows.\n",
        "\n",
        "The orthogonal inverse DCT of type 2 is “idct”:\n",
        "\n"
      ],
      "metadata": {
        "id": "Fy4_dQdEptwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=scipy.fftpack.idct(y,type=2,axis=1,norm='ortho') "
      ],
      "metadata": {
        "id": "yAROdOGHpweB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions are only 1-dimensional. To obtain a **2-dimensional DCT** , we must first replace all rows by their DCT , and then the columns by their respective DCT. This will be achieved simply with the “axis” argument, with x 2-dimensional now,"
      ],
      "metadata": {
        "id": "_O9nSWE1pyr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=scipy.fftpack.dct(x,type=2,axis=1,norm='ortho')\n",
        "y=scipy.fftpack.dct(y,type=2,axis=0,norm='ortho')"
      ],
      "metadata": {
        "id": "RxEEaBUNpWvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Python Examples:**\n",
        "##**Audio Example:**\n",
        "At first a 1-dimensional example for the **Audio-Signal of microphone**. It reads blocks of length “dctlen”, computes the DCT through\n",
        "\n"
      ],
      "metadata": {
        "id": "CQK5VprSWbvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=scipy.fftpack.dct(samples[0:dctlen])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "lGhq_9q0Wm0U",
        "outputId": "d8c871ea-9402-42d2-c580-132c9d4de125"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-01176e863526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdctlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "and converts its magnitude in dB, with:\n"
      ],
      "metadata": {
        "id": "jPT182y5Wk_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "20*np.log10(np.abs(y)))"
      ],
      "metadata": {
        "id": "ljb0NZXVWxmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These dB values for every DCT coefficient respective every subband are displayed then as live plot :\n",
        "\n",
        "*python pyrecdctanimation.py*"
      ],
      "metadata": {
        "id": "Gsgnx85vW0FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GuNtbJz5tW6e",
        "outputId": "4ad88d9a-0445-4658-99e6-545bbabaf298"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20464dcb-13af-496e-8b48-fb35bdb2cfe4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20464dcb-13af-496e-8b48-fb35bdb2cfe4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pyrecdctanimation.py to pyrecdctanimation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention**: In the horizontal axis we see 1024 DCT coefficients resp. subbands. These are now **no longer symmetric** around the center but the Nyquist frequency is now on right end. Thus we use our DCT **coefficients optimal** (nothing is double).\n",
        "\n",
        "**Note**: With whistling, like with the FFT, we obtain peaks in  spectrum, hence the principle of spectral decomposition  remains the same."
      ],
      "metadata": {
        "id": "lMtPhswtW6aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Video example:**\n",
        "We apply the DCT to a whole frame (the “Green” component), first to the rows , then to the columns, then we compute the magnitude and display it, with:"
      ],
      "metadata": {
        "id": "-3cJ31HpXFpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.fftpack as sft\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "[retval, frame] = cap.read()\n",
        "\n",
        "frame=sft.dct(frame[:,:,1]/255.0,axis=1,norm='ortho') \n",
        "frame=np.abs(sft.dct(frame,axis=0,norm='ortho'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "YZ-02OP6XKMR",
        "outputId": "287a0d79-3d19-4000-fe1d-32d138bd789a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-854af79ad4ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ortho'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ortho'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemented in:\n",
        "\n",
        "*python videorecdctdisp.py*\n",
        "\n"
      ],
      "metadata": {
        "id": "FYvofou3XN00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vzZmKjaptIRJ",
        "outputId": "c095931f-28a7-46bc-c536-5e95fdf5008d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6e5aeb4-7d0f-43ac-8608-dcb0b1f0f4aa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6e5aeb4-7d0f-43ac-8608-dcb0b1f0f4aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving videorecdctdisp.py to videorecdctdisp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**: Like for the case of the DFT, the **brightness** in the display indicates the **magnitude** of a frequency component, its **position** in the display indicates its **frequency**.\n",
        "\n",
        "**Observe**: Similar to the Audio example we observe **no** longer the **symmetry**. The whole frame is used and no duplication is there. By holding a fine pattern in front of our camera again it shows the typical point-chain pattern, like with the FFT. The **basic function remains therefore the same**."
      ],
      "metadata": {
        "id": "_VXAHveqXRPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Example of DCT low pass-filter:**\n",
        "We can now **implement** a low pass filter in the DCT domain, similar to the FFT, by the use of an **appropriate mask**. We just have to consider that there is no longer the symmetry in the spectrum. Thus the mask design becomes even simpler. We now use vectors, which at the beginning consist of ones in the pass band, and then zeros in the stop band.\n",
        "\n",
        "##**In Python:**"
      ],
      "metadata": {
        "id": "s0yzhsGxXkm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import cv2\n",
        "r=480\n",
        "c=640\n",
        "#For rows: \n",
        "Mr=np.ones((r,1)) \n",
        "Mr[int(r/4.0):r,0]=np.zeros(int(3.0/4.0*r)) \n",
        "#For columns: \n",
        "Mc=np.ones((1,c)) \n",
        "Mc[0,int(c/4.0):c]=np.zeros(int(3.0/4.0*c)); \n",
        "#Together: \n",
        "M=np.dot(Mr,Mc)\n",
        "plt.imshow(M)\n",
        "plt.title(\"Low-Pass Mask for the 2D-DCT\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "SDcv47eDXxuP",
        "outputId": "06d313fb-b973-42a2-8320-176651213047"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We see**: We only need to define in the upper left edge of our pass band , no longer in all edges .Due to the fact that we practically “see” only the upper left quarter of our DFT spectrum, the band pass appears in both dimensions, twice as big.\n",
        "\n",
        "Implemention with:\n",
        "\n",
        "*python videorecdct0idctdisp.py*\n",
        "\n",
        "(Comparison with the FFT:\n",
        "*python videorecfft0ifftdisp.py*)"
      ],
      "metadata": {
        "id": "iPHC5koqXr8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**: We see in fact a low pass filtered video, smoother and more blurred , with “**ringing artefacts**”, therefore **lines along edges**, completely similar to the FFT."
      ],
      "metadata": {
        "id": "mYkh2QsWYMNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Example: Block by Block DCT**\n",
        "The ringing artefacts occur, because all zero-set DCT coefficients affect the **whole image** through the size of the transform. In this way, we can no longer process **parts of of frames independent from other parts**. This becomes more important in video coding, for the so called “motion compensation”. Therefore in the MPEG video coders, and also in the JPEG image coders, a DCT of size of **8 pixels x 8 pixels** is used. There the image is first divided into a “Mosaic” of **blocks of size 8 pixels x 8 pixels**, and then  the 2-dimensional DCT is applied separately to each of these blocks.\n",
        "\n",
        "We could achieve this block-wise application of the DCT with use of  a “for” loop, but this would be very slow in Python. To implement this **block-wise processing**, we instead apply a trick: We reshape our frames to a **width of only 8 pixels** (and corresponding larger height), where we **wrap** every line **after every 8 pixels**. We apply the DCT to every such row. Afterwards we return it again to the original shape. \n",
        "\n",
        "In Python there is a function for that:"
      ],
      "metadata": {
        "id": "ivGuQIIeYUGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy.reshape(Matrix, (new shape))"
      ],
      "metadata": {
        "id": "YpmRnT9MYsQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Python Example:**\n",
        "Example for a block size of 2x2 pixels:"
      ],
      "metadata": {
        "id": "hqqVH0C3YwAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.fftpack as sft\n",
        "F=np.arange(16)*1.0\n",
        "F=np.reshape(F,(-1,4))\n",
        "#Original Matrix:\n",
        "F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYxJdQZMY0FX",
        "outputId": "721f4d87-a95b-41f5-9bc0-5acdaf607570"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape the matrix in rows of width 2:\n",
        "F=np.reshape(F,(-1,2))\n",
        "#The “-1” means: as many rows as necessary.\n",
        "F "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiILEGKBY3-k",
        "outputId": "db6e0170-342e-4a2b-dc8a-dbe57c17555f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.],\n",
              "       [ 2.,  3.],\n",
              "       [ 4.,  5.],\n",
              "       [ 6.,  7.],\n",
              "       [ 8.,  9.],\n",
              "       [10., 11.],\n",
              "       [12., 13.],\n",
              "       [14., 15.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can now apply the **DCT** to this matrix with the argument “axis=1” (for the rows). The function processes **all these rows** automatically: "
      ],
      "metadata": {
        "id": "6k_GYNkXY7ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y=sft.dct(F,axis=1,norm='ortho')\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usDLeIKtY__6",
        "outputId": "33e9f39c-4053-499b-f20d-6471b89f0a3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.70710678, -0.70710678],\n",
              "       [ 3.53553391, -0.70710678],\n",
              "       [ 6.36396103, -0.70710678],\n",
              "       [ 9.19238816, -0.70710678],\n",
              "       [12.02081528, -0.70710678],\n",
              "       [14.8492424 , -0.70710678],\n",
              "       [17.67766953, -0.70710678],\n",
              "       [20.50609665, -0.70710678]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y now contains the DCT coefficients of each row.\n",
        "\n",
        "Following this we can apply our **filter-mask** for the rows. We multiply every row with the corresponding value of the row-mask. We can implement it through **matrix multiplication**, such that we multiply a diagonal matrix from right hand side, which contains the row-mask on its diagonal,"
      ],
      "metadata": {
        "id": "iQV6gjNNZCKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Mr=np.array([1,0])\n",
        "Y=np.dot(Y,np.diag(Mr))\n",
        "Y "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtVUufVBZNuC",
        "outputId": "0e46e9d0-ae10-4ea7-d20e-16b443f3db2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.70710678,  0.        ],\n",
              "       [ 3.53553391,  0.        ],\n",
              "       [ 6.36396103,  0.        ],\n",
              "       [ 9.19238816,  0.        ],\n",
              "       [12.02081528,  0.        ],\n",
              "       [14.8492424 ,  0.        ],\n",
              "       [17.67766953,  0.        ],\n",
              "       [20.50609665,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following this we reshape the matrix back to its original width,"
      ],
      "metadata": {
        "id": "NheKvPJFZSOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y=np.reshape(Y,(-1,4)) \n",
        "Y "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dWszbZUZUWC",
        "outputId": "5e914d0a-bdfb-460b-d6ef-78b5d3b62a1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.70710678,  0.        ,  3.53553391,  0.        ],\n",
              "       [ 6.36396103,  0.        ,  9.19238816,  0.        ],\n",
              "       [12.02081528,  0.        , 14.8492424 ,  0.        ],\n",
              "       [17.67766953,  0.        , 20.50609665,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to apply the DCT along the columns. For the reshaping **in columns** of the block-length we can use the same approach, if we apply it simply to the **transposed matrix** (because here the rows and column-indices are simply interchanged), hence we get the same steps as above, just on the transpose matrix,"
      ],
      "metadata": {
        "id": "KGvpAJxwo7Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y=Y.T\n",
        "Y=np.reshape(Y,(-1,2))\n",
        "Y=sft.dct(Y,axis=1,norm='ortho')\n",
        "Mc=np.array([1,0])\n",
        "Y=np.dot(Y,np.diag(Mc))\n",
        "Y=np.reshape(Y,(-1,4))\n",
        "Y=Y.T\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZsD2_X8pCX-",
        "outputId": "cd963322-168c-46d6-d99b-8a4aa222bed6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.53553391,  0.        ,  6.36396103,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [14.8492424 ,  0.        , 17.67766953,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matrix Y now contains the **DCT coefficients** of our **blocks** of size 2x2 pixels, including the application of our **low pass mask**! Here, just the “DC”value remains for every block ."
      ],
      "metadata": {
        "id": "tCoJ2azGpHm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Python example to Video low pass-Filtering with Block by block DCT:**\n",
        "Implementation with :\n",
        "\n",
        "*python videorecdctblocks0idctdisp.py*"
      ],
      "metadata": {
        "id": "LDslyErjpPFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uY8AbVXOtkUz",
        "outputId": "2722a8c9-4193-4d5e-8336-57f90b2df77a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c5baaec-1528-49d0-9f5c-c3ce576c6396\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c5baaec-1528-49d0-9f5c-c3ce576c6396\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving videorecdctblocks0idctdisp.py to videorecdctblocks0idctdisp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**: In the original we see the 8x8 pixel block raster as white grid. \n",
        "\n",
        "In the 2D-DCT image we now see many small 2D-DCT-spectra, corresponding to the 8 pixel x 8 pixel block division.\n",
        "\n",
        "In the resulting video of the inverse 2D DCT the  ringing artifacts indeed disappeared, but now we have “blocking” artifacts, which are familiar artifacts from MPEG and JPEG Coding. "
      ],
      "metadata": {
        "id": "kCAkUBb_pUeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have now decreased the number of DCT coefficients by a factor of 4*4=16 (good compression), but at the price of these artifacts. When we keep more DCT coefficients, we will get better quality.\n",
        "\n",
        "For **color**, this processing is done separately for the **Y-component** and the downsampled **color components** U, V , or Cr, Cb, downsampled e.g. according to the 4:2:0 scheme."
      ],
      "metadata": {
        "id": "hSYny-bfpZns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For transmission or storage we need to convert the subband values into bits, and for that we need to apply quantization. We can now simply quantize a suitable subset of **DCT coefficients** resp. **subband values, and transfer them to decoder**. Because the DCT decomposes our image into different spatial frequency components, we can choose the quantization step size according to the Contrast Sensitivity Function of the eye, which tells us the sensitivity of the eye for each spatial frequency component, in such a way that the eye does not see quantization artifacts."
      ],
      "metadata": {
        "id": "XJSQKWb5pgwN"
      }
    }
  ]
}